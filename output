import pandas as pd
import numpy as np

# Load MovieLens dataset (100k dataset)
data = Dataset.load_builtin('ml-100k')

# Split data into training and testing sets
trainset, testset = train_test_split(data, test_size=0.2)

# Build an SVD model
svd = SVD()

# Train the model on the training set
svd.fit(trainset)

# Predict ratings for the test set
predictions = svd.test(testset)

# Calculate the RMSE (Root Mean Squared Error)
rmse = accuracy.rmse(predictions)
print(f"RMSE: {rmse}")

# Function to get top-N recommendations for a user
def get_top_n(predictions, n=10):
    # Map the predictions to each user
    top_n = {}
    for uid, iid, true_r, est, _ in predictions:
        if uid not in top_n:
            top_n[uid] = []
        top_n[uid].append((iid, est))

    # Sort the predictions for each user and get the top-N
    for uid, user_ratings in top_n.items():
        user_ratings.sort(key=lambda x: x[1], reverse=True)
        top_n[uid] = user_ratings[:n]
    
    return top_n

# Get top-N recommendations for all users
top_n = get_top_n(predictions, n=10)

# Save top-N recommendations to a CSV file
top_n_df = []
for user_id, recommendations in top_n.items():
    for movie_id, predicted_rating in recommendations:
        top_n_df.append([user_id, movie_id, predicted_rating])

# Convert to DataFrame and save to CSV
df = pd.DataFrame(top_n_df, columns=['User ID', 'Movie ID', 'Predicted Rating'])
df.to_csv('movie_recommendations.csv', index=False)

print(f"Top-10 recommendations for each user saved in 'movie_recommendations.csv'.")

# Visualizing first few entries from the result
print("\nSample top-10 recommendations:")
print(df.head())

# Example: Display top-10 recommendations for User 1
user_id = '1'
print(f"\nTop-10 recommendations for User {user_id}:")
for movie_id, predicted_rating in top_n[user_id]:
    print(f"Movie ID: {movie_id}, Predicted Rating: {predicted_rating}")

# Cross-validation to evaluate the model's performance
cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

# Hyperparameter tuning (optional)
from surprise import GridSearchCV
param_grid = {
    'n_factors': [50, 100, 200],
    'lr_all': [0.002, 0.005, 0.01],
    'reg_all': [0.02, 0.05, 0.1]
}

grid_search = GridSearchCV(SVD, param_grid, measures=['RMSE'], cv=3)
grid_search.fit(data)

# Get the best parameters and best RMSE score
print(f"\nBest RMSE: {grid_search.best_score['rmse']}")
print(f"Best parameters: {grid_search.best_params['rmse']}")
